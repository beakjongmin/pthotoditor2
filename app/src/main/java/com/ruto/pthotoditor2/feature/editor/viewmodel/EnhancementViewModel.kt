package com.ruto.pthotoditor2.feature.editor.viewmodel

import android.content.Context
import android.graphics.Bitmap
import android.util.Log
import android.widget.Toast
import androidx.lifecycle.ViewModel
import androidx.lifecycle.viewModelScope
import com.ruto.photoeditor2.core.image.ml.SuperResolutionHelper
import com.ruto.pthotoditor2.core.image.opencv.OpenCvFilters
import com.ruto.pthotoditor2.core.image.opencv.OpenCvFilters.applyFilterWithMask
import com.ruto.pthotoditor2.core.image.opencv.OpenCvUtils
import com.ruto.pthotoditor2.core.image.opencv.OpenCvUtils.toSoftAlphaMask
import com.ruto.pthotoditor2.core.image.segmentation.process.dslr.ensureSoftwareConfig
import com.ruto.pthotoditor2.core.image.segmentation.process.facedetection.SelfieSegmentor
import com.ruto.pthotoditor2.core.image.segmentation.process.facedetection.SelfieSegmentor.detectFaceWithHairRegion
import com.ruto.pthotoditor2.core.image.segmentation.process.mask.FacialPartMaskUtil.createEyeAndMouthMasks
import com.ruto.pthotoditor2.core.image.segmentation.process.mask.MasktoAlpha
import com.ruto.pthotoditor2.feature.editor.model.UpScaletype
import dagger.hilt.android.lifecycle.HiltViewModel
import kotlinx.coroutines.Dispatchers
import kotlinx.coroutines.flow.MutableStateFlow
import kotlinx.coroutines.flow.asStateFlow
import kotlinx.coroutines.launch
import kotlinx.coroutines.withContext
import javax.inject.Inject


@HiltViewModel
class EnhancementViewModel @Inject constructor() : ViewModel() {


    private val _isProcessing = MutableStateFlow(false)
    val isProcessing = _isProcessing.asStateFlow()

    fun getEffectTypes(): List<UpScaletype> = UpScaletype.values().toList()


    fun applyPortraitEffect(
        context: Context,
        original: Bitmap?,
        type: UpScaletype,
        onResult: (Bitmap) -> Unit
    ) {
        if (original == null) return

        viewModelScope.launch(Dispatchers.Default) {
            try {
                withContext(Dispatchers.Main) { _isProcessing.value = true }

                val safeOriginal = original.ensureSoftwareConfig()

                val mask = SelfieSegmentor.segment(safeOriginal)
                val maskBitmap = toSoftAlphaMask(mask, safeOriginal.width, safeOriginal.height)

                // ‚úÖ Î®∏Î¶¨ ÏòÅÏó≠ Ï¢åÌëú Í≥ÑÏÇ∞
                val faceRect = detectFaceWithHairRegion(safeOriginal)

                if (faceRect == null) {

                    withContext(Dispatchers.Main) {
                        Toast.makeText(context, "ÏñºÍµ¥ÏùÑ Ïù∏ÏãùÌï†Ïàò ÏóÜÏäµÎãàÎã§.", Toast.LENGTH_SHORT).show()
                        _isProcessing.value = false
                        onResult(original)
                    }
                    return@launch
                }

                val croppedHead = Bitmap.createBitmap(safeOriginal, faceRect.left, faceRect.top, faceRect.width(), faceRect.height())
                Log.d("EnhancementViewModel", "üìå ÏñºÍµ¥+Ìó§Ïñ¥ ÏòÅÏó≠ ÌÅ¨Î°≠ ÏôÑÎ£å: ${croppedHead.width}x${croppedHead.height} at (${faceRect.left}, ${faceRect.top})")


                // ‚úÖ ÏóÖÏä§ÏºÄÏùº
                val upscaled = SuperResolutionHelper.upscale(context, croppedHead)
                Log.d("EnhancementViewModel", "üÜô ÏóÖÏä§ÏºÄÏùº ÏôÑÎ£å: ${upscaled.width}x${upscaled.height}")


                // üß† Îàà/ÏûÖ ÎßàÏä§ÌÅ¨ ÏÉùÏÑ±
                val (eyeMask, mouthMask) = createEyeAndMouthMasks(croppedHead)
                if (eyeMask == null || mouthMask == null) {
                    Log.w("EnhancementViewModel", "Îàà ÎòêÎäî ÏûÖ ÎßàÏä§ÌÅ¨ ÏÉùÏÑ± Ïã§Ìå®. ÌïÑÌÑ∞ Ï†ÅÏö© Í±¥ÎÑàÎúÄ")
                    withContext(Dispatchers.Main) {
                        _isProcessing.value = false
                        onResult(original)
                    }
                    return@launch
                }

                val argbEyeMask = MasktoAlpha.toAlphaDrawableMask(eyeMask)
                val argbMouthMask = MasktoAlpha.toAlphaDrawableMask(mouthMask)

                //ÎîîÎ≤ÑÍπÖÏö© ÏûÑÏãú ÏΩîÎìú
//                fun convertAlphaToARGB(mask: Bitmap): Bitmap {
//                    val argbBitmap = Bitmap.createBitmap(mask.width, mask.height, Bitmap.Config.ARGB_8888)
//                    val canvas = Canvas(argbBitmap)
//                    val paint = Paint().apply { color = Color.WHITE }
//                    canvas.drawBitmap(mask, 0f, 0f, paint) // Ìù∞ÏÉâÏúºÎ°ú Ï±ÑÏö¥ ÏïåÌååÎ•º Í∑∏ÎåÄÎ°ú Í∑∏Î¶º
//                    return argbBitmap
//                }
//                val debugimage = convertAlphaToARGB(upscaledMouthMask)
//                saveUpscaledImageToGallery(context,debugimage)
//                Log.w("EnhancementViewModel", "upscaledEyeMask ${upscaledEyeMask.width} * ${upscaledEyeMask.height} ")
                //alpha mask
                val upscaledEyeMask = Bitmap.createScaledBitmap(argbEyeMask, upscaled.width, upscaled.height, false)
                val upscaledMouthMask = Bitmap.createScaledBitmap(argbMouthMask, upscaled.width, upscaled.height, false)

                val croppedMask = Bitmap.createBitmap(maskBitmap, faceRect.left, faceRect.top, faceRect.width(), faceRect.height())
                val maskUpscaled = Bitmap.createScaledBitmap(croppedMask, upscaled.width, upscaled.height, false)

                // ‚úÖ ÌïÑÌÑ∞ Ï†ÅÏö©
                val filtered = when (type) {
                    UpScaletype.SHARP -> {
                        applyFilterWithMask(context,upscaled, maskUpscaled,) {
                            OpenCvFilters.applySharp(it)
                        }
                    }
                    UpScaletype.SOFT -> {
                        applyFilterWithMask(context,upscaled, maskUpscaled) {
                            OpenCvFilters.applySoft(it)
                        }
                    }
                    UpScaletype.CLEAR -> {
                        applyFilterWithMask(context,upscaled, maskUpscaled) {
                            OpenCvFilters.applyClear(it)
                        }
                    }
                    UpScaletype.NATURAL -> {
                        applyFilterWithMask(context,upscaled, maskUpscaled) {
                            OpenCvFilters.applyNatural(it)
                        }
                    }
                    UpScaletype.UPSCALEONLY -> {
                        upscaled
                    }
                }

                val toneCorrected = OpenCvUtils.matchToneByMean(upscaled, filtered)
//                saveUpscaledImageToGallery(context,filtered)
                // ‚úÖ Îã§Ïãú ÏõêÎûò ÌÅ¨Í∏∞Î°ú Îã§Ïö¥Ïä§ÏºÄÏùº (ÏõêÎûò ÌÅ¨Í∏∞: headRect)
                val restoredSize = Bitmap.createScaledBitmap(toneCorrected, faceRect.width(), faceRect.height(), false )

                // ‚úÖ Ìï¥Îãπ ÏúÑÏπòÏóê Î∏îÎ†åÎî©
                val maskRegion = Bitmap.createBitmap(maskBitmap, faceRect.left, faceRect.top, faceRect.width(), faceRect.height())

                val maskRestored = Bitmap.createScaledBitmap(maskRegion, faceRect.width(), faceRect.height(), false )

                val final = OpenCvUtils.blendCroppedRegionBack(
                    original = safeOriginal,
                    upscaledPerson = restoredSize,
                    mask = maskRestored,
                    offsetX = faceRect.left,
                    offsetY = faceRect.top
                )

                Log.d("EnhancementViewModel", "üß™  Ï≤òÎ¶¨Îêú Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞: ${final.width}x${final.height}")

                withContext(Dispatchers.Main) {
                    onResult(final)
                    _isProcessing.value = false
                }

            } catch (e: Exception) {
                Log.e("EnhancementViewModel", "‚ùå Ïù∏Î¨º Ìö®Í≥º Ïã§Ìå®: ${e.message}", e)
                withContext(Dispatchers.Main) { _isProcessing.value = false }
            }
        }
    }


}
